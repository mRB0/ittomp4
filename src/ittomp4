#!/usr/bin/env python
# -*- coding: utf-8-unix -*-

from __future__ import division

import sys
import logging
import contextlib
import math
import struct
import threading
from Queue import Queue, Empty, Full

import cairo
import decode_mod


from sys import platform as _platform
if _platform == 'linux' or _platform == 'linux2':
    import cairofont_freetype as cairofont
elif _platform == 'win32':
    import cairofont_windows as cairofont
elif _platform == 'darwin':
    import cairofont_osx as cairofont

FONT_FACE = cairofont.load_font('Comic Sans MS')


@contextlib.contextmanager
def cairo_surface(*image_surface_args):
    surface = cairo.ImageSurface(*image_surface_args)
    yield surface
    del surface

@contextlib.contextmanager
def cairo_context(surface):
    context = cairo.Context(surface)
    yield context
    del context

class VideoLayout(object):
    def __init__(self, fps):
        self.fps = fps
        self.step = 0

    def build_frame(self):
        barwidth = 100
        step = 10

        i = self.step
        self.step += 1

        with cairo_surface(cairo.FORMAT_ARGB32, 1920, 1080) as surface:
            with cairo_context(surface) as ctx:

                ctx.new_path()
                ctx.rectangle(0, 0, 1920, 1080)
                ctx.set_source_rgb(math.cos(i / 240 * (math.pi * 2)) / 2 + 0.5, 0, math.sin(i / 180 * (math.pi * 2)) / 2 + 0.5)
                ctx.fill()

                horizbar_y_ctr = (1080 / 2) + (int(math.cos(i / 240 * (math.pi * 2)) * (1080 / 2 * .8)))
                max_extent = int(1080 * .08 / 2)

                for h in xrange(max_extent, 0, -1):
                    ctx.new_path()
                    ctx.rectangle(0, horizbar_y_ctr - h, 1920, h * 2)
                    ctx.set_source_rgba(1, 1, 1, (max_extent - h) / pow(max_extent, 2))
                    ctx.fill()



                ctx.new_path()

                if 1920 - ((i * step) % 1920) < barwidth:
                    ctx.rectangle((i * step) % 1920 - 1920, 0, barwidth, 1080)
                ctx.rectangle((i * step) % 1920, 0, barwidth, 1080)

                ctx.set_source_rgb(0.25, 1, 0.25)
                ctx.fill()


                ctx.set_font_face(FONT_FACE)
                ctx.set_font_size(128)
                ctx.set_source_rgb(1, 1, 1)

                for pos, ltr in enumerate('  YOU ARE FULL OF BOMBS AND/OR KEYS'):
                    x = 1920 - i * step + (128 * pos)
                    y = (1080 / 2) - (1080 * 0.2 * math.sin((x + (i * step/4)) * math.pi / 1020))

                    ctx.move_to(x, y)
                    ctx.show_text(ltr)

            surface_data = str(surface.get_data())

            return surface_data

class ModDecoder(object):

    def __init__(self, mod_filename):
        self.fps = 48000
        self._filename = mod_filename
        self.module = decode_mod.Module(self._filename)

    def close(self):
        if self.module is not None:
            self.module.close()
            self.module = None
        
    def get_frames(self, count):
        samples_buffer_raw = self.module.decode(count)
        if samples_buffer_raw is None:
            return None
        samples_buffer = ''.join([struct.pack('<h', samp) for samp in samples_buffer_raw])

        return samples_buffer
        
    def get_pattern_state(self):
        pass

class Synchronizer(object):
    DONE = object()
    
    def __init__(self, audio_decoder, video_layout):
        self._audio_decoder = audio_decoder
        self._video_layout = video_layout
        
        self._video_frames_per_second = video_layout.fps
        self._audio_frames_per_second = audio_decoder.fps
        self._audio_frames_per_video_frame = self._audio_frames_per_second / self._video_frames_per_second
        
        self._video_frames_produced = 0
        self._audio_frames_produced = 0

        self._video_queue = Queue(1)
        self._audio_queue = Queue()
        
        self._request_condition = threading.Condition()

    def _request_next_frame(self):
        with self._request_condition:
            self._request_condition.notify()
            
    def video_frames(self):
        while True:
            logging.debug("Fetch a video frame")
            try:
                frame_data = self._video_queue.get(False)
            except Empty:
                logging.debug("Request next video frame and wait")
                self._request_next_frame()
                frame_data = self._video_queue.get()
            
            if frame_data is Synchronizer.DONE:
                break
            yield frame_data

    def audio_frames(self):
        while True:
            logging.debug("Fetch audio frames")
            try:
                frame_data = self._audio_queue.get(False)
            except Empty:
                logging.debug("Request next audio frame and wait")
                self._request_next_frame()
                frame_data = self._audio_queue.get()

            if frame_data is Synchronizer.DONE:
                break
            yield frame_data


    def _audio_frames_to_next_video_frame(self):
        overshoot = self._audio_frames_produced % self._audio_frames_per_video_frame
        return int(math.ceil(self._audio_frames_per_video_frame - overshoot))
        
    
    def _run(self):
        try:
            while True:
                with self._request_condition:
                    self._request_condition.wait()
                    logging.debug("Produce frame: audio queue size = {}, video queue size = {}".format(self._audio_queue.qsize(), self._video_queue.qsize()))
                    
                    audio_frame_count = self._audio_frames_to_next_video_frame()
                    logging.debug("Produce {} audio frames".format(audio_frame_count))

                    audio_frames = self._audio_decoder.get_frames(audio_frame_count)
                    if audio_frames is None:
                        break

                    # TODO: do this only if supported by audio decoder
                    pattern_state = self._audio_decoder.get_pattern_state()

                    video_frame = self._video_layout.build_frame() # TODO: pass pattern state, vu state, etc.
                    self._audio_queue.put(audio_frames)
                    self._video_queue.put(video_frame)
                
        finally:
            self._video_queue.put(Synchronizer.DONE)
            self._audio_queue.put(Synchronizer.DONE)

    def start(self):
        self._thread = threading.Thread(target=self._run, name="synchronizer")
        self._thread.daemon = True
        self._thread.start()
        


class VideoSource(object):
    def __init__(self, synchronizer):
        self._synchronizer = synchronizer

    def frames(self):
        for f in self._synchronizer.video_frames():
            yield f

    
class AudioSource(object):
    def __init__(self, synchronizer):
        self._synchronizer = synchronizer

    def frames(self):
        for f in self._synchronizer.audio_frames():
            yield f

            
if __name__ == '__main__':
    import logging
    logging.basicConfig(level=logging.INFO, format="%(asctime)s %(threadName)s %(levelname)-7s %(message)s")

    import videofeeder

    synchronizer = Synchronizer(ModDecoder(sys.argv[1]), VideoLayout(60))
    audio_source = AudioSource(synchronizer)
    video_source = VideoSource(synchronizer)

    synchronizer.start()
    
    videofeeder.Encoder(audio_source, video_source).run()

